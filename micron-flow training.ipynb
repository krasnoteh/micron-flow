{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cebfc5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from torchvision.io import decode_image, decode_jpeg\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision.models.optical_flow import raft_large\n",
    "from torchvision.utils import flow_to_image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch import Tensor\n",
    "import random\n",
    "import time\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef9dff1a-8c5f-47c2-965c-72f85d51f8f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = (152, 240)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f48e15e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class StreamLoader:\n",
    "    def __init__(self, dataset: torch.utils.data, batch_size: int, min_cache_size: int, max_cache_size: int, cache_update_probability: float):\n",
    "        \n",
    "        self.dataset = dataset\n",
    "        self.batch_size = batch_size\n",
    "        self.min_cache_size = min_cache_size\n",
    "        self.max_cache_size = max_cache_size\n",
    "        self.cache_update_probability = cache_update_probability\n",
    "        self.preprocessor_batch_size = 1024\n",
    "\n",
    "        self.cache = []\n",
    "\n",
    "        self.make_processing_queue()\n",
    "\n",
    "    def make_processing_queue(self):\n",
    "        self.processing_queue = list(range(0, len(self.dataset)))\n",
    "        random.shuffle(self.processing_queue)\n",
    "\n",
    "    def fill_cache_one_batch(self):\n",
    "        print(\"processing new batch\")\n",
    "        preprocessor_batch = []\n",
    "        while len(preprocessor_batch) < self.preprocessor_batch_size:\n",
    "            if len(self.processing_queue) == 0:\n",
    "                self.make_processing_queue()\n",
    "\n",
    "            idx = self.processing_queue.pop()\n",
    "            preprocessor_batch.append(self.dataset[idx])\n",
    "\n",
    "        processed_batch = self.preprocess_batch(preprocessor_batch)\n",
    "        self.cache.extend(processed_batch)\n",
    "\n",
    "    def fill_cache(self):\n",
    "        while len(self.cache) <= self.min_cache_size:\n",
    "            self.fill_cache_one_batch()\n",
    "\n",
    "    def __iter__(self):\n",
    "        return self\n",
    "\n",
    "    def __next__(self):\n",
    "        if len(self.cache) <= self.min_cache_size:\n",
    "            self.fill_cache()\n",
    "\n",
    "        num_tensors = len(self.cache)\n",
    "        chosen_indices = random.sample(range(num_tensors), self.batch_size)\n",
    "        \n",
    "        batch = []\n",
    "        updated_cache = []\n",
    "        \n",
    "        for i, obj in enumerate(self.cache):\n",
    "            if i in chosen_indices:\n",
    "                batch.append(obj)\n",
    "                if random.random() >= self.cache_update_probability:\n",
    "                    updated_cache.append(obj)\n",
    "            else:\n",
    "                updated_cache.append(obj)\n",
    "        \n",
    "        self.cache = updated_cache\n",
    "\n",
    "        batch = self.stack_batch(batch)\n",
    "\n",
    "        return batch\n",
    "    \n",
    "    def preprocess_batch(self, batch):\n",
    "        frames_A = []\n",
    "        frames_B = []\n",
    "        flows = []\n",
    "        for frame_A, frame_B, flow in batch:\n",
    "            frames_A.append(frame_A)\n",
    "            frames_B.append(frame_B)\n",
    "            flows.append(flow)\n",
    "            \n",
    "        frames_A = decode_jpeg(frames_A, device = device)\n",
    "        frames_B = decode_jpeg(frames_B, device = device)\n",
    "        flows = decode_jpeg(flows, device = device)\n",
    "        \n",
    "        frames_A = [frame_A.type(torch.float32) / 256.0 for frame_A in frames_A]\n",
    "        frames_B = [frame_B.type(torch.float32) / 256.0 for frame_B in frames_B]\n",
    "        flows = [flow[:-1, ...].type(torch.float32) / 256.0 for flow in flows]\n",
    "\n",
    "        batch = [(frame_A, frame_B, flow) for frame_A, frame_B, flow in zip(frames_A, frames_B, flows)]\n",
    "    \n",
    "        return batch\n",
    "        \n",
    "    \n",
    "    def stack_batch(self, batch):\n",
    "        frames_A = []\n",
    "        frames_B = []\n",
    "        flows = []\n",
    "        for frame_A, frame_B, flow in batch:\n",
    "            frames_A.append(frame_A)\n",
    "            frames_B.append(frame_B)\n",
    "            flows.append(flow)\n",
    "            \n",
    "        return torch.stack(frames_A, axis = 0), torch.stack(frames_B, axis = 0), torch.stack(flows, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "974dd1f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FlowImageDataset(Dataset):\n",
    "    def __init__(self, dataset_dir):\n",
    "        self.dataset_dir = dataset_dir\n",
    "\n",
    "        self.frames_A_dir = os.path.join(dataset_dir, 'frames_A')\n",
    "        self.frames_B_dir = os.path.join(dataset_dir, 'frames_B')\n",
    "        self.flow_dir = os.path.join(dataset_dir, 'flows')\n",
    "        \n",
    "        self.image_names = sorted(os.listdir(self.frames_A_dir))\n",
    "                \n",
    "    def __len__(self):\n",
    "        return len(self.image_names)\n",
    "    \n",
    "    def load_bytes(self, path):\n",
    "        with open(path, \"rb\") as f:\n",
    "            image_bytes = f.read()\n",
    "            \n",
    "        return torch.tensor(list(image_bytes), dtype=torch.uint8)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        frame_A = self.load_bytes(os.path.join(self.frames_A_dir, self.image_names[idx]))\n",
    "        frame_B = self.load_bytes(os.path.join(self.frames_B_dir, self.image_names[idx]))\n",
    "        flow = self.load_bytes(os.path.join(self.flow_dir, self.image_names[idx]))\n",
    "        \n",
    "        return frame_A, frame_B, flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d773bba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = FlowImageDataset(\"moments_medium_std2\")\n",
    "loader = StreamLoader(dataset = dataset, batch_size = 32, min_cache_size = 10000, max_cache_size = 15000,\n",
    "                      cache_update_probability = 0.5)\n",
    "\n",
    "A, B, flow = next(iter(loader))\n",
    "print(A.shape, flow.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5034eab3-97eb-407c-add4-c16f3b27bf4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "A, B, flow = next(iter(loader))\n",
    "print(A.shape, flow.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c098adc-c77b-4145-a8b2-76f2dbc85ee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MobileNetV2ConvLayer(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride=1, groups=1, activation=True):\n",
    "        super().__init__()\n",
    "        padding = (kernel_size - 1) // 2\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size, stride,padding, groups=groups, bias=False)\n",
    "        self.bn = nn.BatchNorm2d(out_channels, eps=0.001, momentum=0.997)\n",
    "        self.activation = nn.ReLU6() if activation else None\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.bn(x)\n",
    "        if self.activation:\n",
    "            x = self.activation(x)\n",
    "        return x\n",
    "\n",
    "class MobileNetV2InvertedResidual(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, stride, expand_ratio):\n",
    "        super().__init__()\n",
    "        hidden_dim = in_channels * expand_ratio\n",
    "        \n",
    "        self.expand_1x1 = MobileNetV2ConvLayer(in_channels, hidden_dim, 1, activation=True)\n",
    "        self.conv_3x3 = MobileNetV2ConvLayer(hidden_dim, hidden_dim, 3, stride=stride, groups=hidden_dim, activation=True)                          \n",
    "        self.reduce_1x1 = MobileNetV2ConvLayer(hidden_dim, out_channels, 1, activation=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "        \n",
    "        x = self.expand_1x1(x)\n",
    "        x = self.conv_3x3(x)\n",
    "        x = self.reduce_1x1(x)\n",
    "        \n",
    "        if x.shape == identity.shape:\n",
    "            x = x + identity\n",
    "        return x\n",
    "        \n",
    "\n",
    "class Backbone(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv_stem = nn.Sequential(\n",
    "            MobileNetV2ConvLayer(3, 32, 3, stride=2),\n",
    "            MobileNetV2ConvLayer(32, 32, 3, groups=32),\n",
    "            MobileNetV2ConvLayer(32, 16, 1, activation=False)\n",
    "        )\n",
    "\n",
    "        self.block1 = MobileNetV2InvertedResidual(16, 24, stride=2, expand_ratio=6)\n",
    "        self.block2 = MobileNetV2InvertedResidual(24, 24, stride=1, expand_ratio=6)\n",
    "        self.block3 = MobileNetV2InvertedResidual(24, 32, stride=2, expand_ratio=6)\n",
    "       \n",
    "        \n",
    "    def forward(self, x):\n",
    "        out1 = self.conv_stem(x)\n",
    "        x = self.block1(out1)\n",
    "        out2 = self.block2(x)\n",
    "        out3 = self.block3(out2)\n",
    "        return out1, out2, out3\n",
    "\n",
    "class CombinedEncoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.backbone = Backbone()\n",
    "\n",
    "        self.image_conv = nn.Conv2d(3, 8, kernel_size=3, padding=1)\n",
    "        self.batch_norm = nn.BatchNorm2d(8)\n",
    "        self.activation = nn.ReLU(inplace=True)\n",
    "\n",
    "    def forward(self, image):\n",
    "        out2, out3, out4 = self.backbone(image)\n",
    "\n",
    "        x = self.image_conv(image)\n",
    "        x = self.batch_norm(x)\n",
    "        out1 = self.activation(x)\n",
    "\n",
    "        return out1, out2, out3, out4\n",
    "\n",
    "class FlowEncoderResidualBlock(nn.Module):\n",
    "    def __init__(self, input_channels, hidden_channels, output_channels):\n",
    "        super(FlowEncoderResidualBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(input_channels, hidden_channels, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(hidden_channels, output_channels, kernel_size=3, padding=1)\n",
    "        self.batch_norm1 = nn.BatchNorm2d(hidden_channels)\n",
    "        self.batch_norm2 = nn.BatchNorm2d(output_channels)\n",
    "        self.residual_conv = nn.Conv2d(input_channels, output_channels, kernel_size=1, bias=False)\n",
    "        self.activation = nn.ReLU(inplace=True)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        residual = self.residual_conv(x)\n",
    "        \n",
    "        x = self.conv1(x)\n",
    "        x = self.batch_norm1(x)\n",
    "        x = self.activation(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.batch_norm2(x)\n",
    "        \n",
    "        x = x + residual\n",
    "        x = self.activation(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "class FlowEncoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.block1 = FlowEncoderResidualBlock(8 * 2, 32, 16)\n",
    "        self.block2 = FlowEncoderResidualBlock(16 * 2 + 16, 32, 16)\n",
    "        self.block3 = FlowEncoderResidualBlock(24 * 2 + 16, 64, 32)\n",
    "        self.block4 = FlowEncoderResidualBlock(32 * 2 + 32, 128, 32)\n",
    "\n",
    "        self.pooling = nn.AvgPool2d(2)\n",
    "        \n",
    "    def forward(self, encoder_A_output, encoder_B_output):\n",
    "        A1, A2, A3, A4 = encoder_A_output\n",
    "        B1, B2, B3, B4 = encoder_B_output\n",
    "\n",
    "        x = torch.cat([A1, B1], axis = 1)\n",
    "        block1_output = self.block1(x)\n",
    "        x = self.pooling(block1_output)\n",
    "\n",
    "        x = torch.cat([A2, B2, x], axis = 1)\n",
    "        block2_output = self.block2(x)\n",
    "        x = self.pooling(block2_output)\n",
    "\n",
    "        x = torch.cat([A3, B3, x], axis = 1)\n",
    "        block3_output = self.block3(x)\n",
    "        x = self.pooling(block3_output)\n",
    "\n",
    "        x = torch.cat([A4, B4, x], axis = 1)\n",
    "        block4_output = self.block4(x)\n",
    "        \n",
    "        return block1_output, block2_output, block3_output, block4_output\n",
    "\n",
    "class FlowRefiner(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(FlowRefiner, self).__init__()\n",
    "        \n",
    "        self.consistency_residual1 = FlowEncoderResidualBlock(32, 64, 32)\n",
    "        self.consistency_residual2 = FlowEncoderResidualBlock(32 + 32, 64, 32)\n",
    "        \n",
    "        self.internal_consistency_residual = FlowEncoderResidualBlock(32, 64, 32)\n",
    "        \n",
    "        self.pooling = nn.AvgPool2d(2)\n",
    "        \n",
    "    def forward(self, input_flow):\n",
    "        \n",
    "        residual_connection = self.consistency_residual1(input_flow)\n",
    "        \n",
    "        x = self.pooling(residual_connection)\n",
    "        x = self.internal_consistency_residual(x)\n",
    "        \n",
    "        x = F.interpolate(\n",
    "            x, \n",
    "            size=residual_connection.shape[2:],\n",
    "            mode='bilinear', \n",
    "            align_corners=False\n",
    "        )\n",
    "        \n",
    "        x = torch.cat([x, input_flow], axis = 1)\n",
    "        x = self.consistency_residual2(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "class UpscaleBlock(nn.Module):\n",
    "    def __init__(self, base_channels, details_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.upsample = nn.Upsample(scale_factor=2, mode=\"bilinear\", align_corners=False)\n",
    "\n",
    "        self.block = FlowEncoderResidualBlock(base_channels + details_channels, out_channels * 2, out_channels)\n",
    "\n",
    "    def forward(self, base, details):\n",
    "        upsampled_base = self.upsample(base)\n",
    "\n",
    "        x = torch.cat([upsampled_base, details], axis = 1)\n",
    "        x = self.block(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "class FlowDecoder(nn.Module):  \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.upscale_block1 = UpscaleBlock(32, 32, 32)\n",
    "        self.upscale_block2 = UpscaleBlock(32, 16, 32)\n",
    "        self.upscale_block3 = UpscaleBlock(32, 16, 16)\n",
    "\n",
    "        self.linear = nn.Conv2d(16, 2, kernel_size=1)\n",
    "        \n",
    "    def forward(self, flows):\n",
    "        f1, f2, f3, f4 = flows\n",
    "        \n",
    "        x = self.upscale_block1(f4, f3)\n",
    "        x = self.upscale_block2(x, f2)\n",
    "        x = self.upscale_block3(x, f1)\n",
    "\n",
    "        x = self.linear(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "\n",
    "class OpticalFlowNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.encoder = CombinedEncoder()\n",
    "        self.flow_encoder = FlowEncoder()\n",
    "        self.flow_decoder = FlowDecoder()\n",
    "        self.flow_refiner = FlowRefiner()\n",
    "\n",
    "    def forward(self, frameA, frameB):\n",
    "        encoder_A_output = self.encoder(frameA)\n",
    "        encoder_B_output = self.encoder(frameB)\n",
    "        flows = self.flow_encoder(encoder_A_output, encoder_B_output)\n",
    "        f1, f2, f3, f4 = flows\n",
    "        f4 = self.flow_refiner(f4)\n",
    "        flows = f1, f2, f3, f4\n",
    "        flow = self.flow_decoder(flows)\n",
    "        \n",
    "        return flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58256158-060c-486e-bd93-6990de2595cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = OpticalFlowNetwork()\n",
    "flow = model(torch.zeros(4, 3, 128, 128), torch.zeros(4, 3, 128, 128))\n",
    "print(flow.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6e62254",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "\n",
    "class VisualDataLogger:\n",
    "    def __init__(self):\n",
    "        self.train_hist = np.array(np.empty([0]))\n",
    "        self.test_hist = np.array(np.empty([0]))\n",
    "        \n",
    "    def reset(self):\n",
    "        self.train_hist = np.array(np.empty([0]))\n",
    "        self.test_hist = np.array(np.empty([0]))\n",
    "        \n",
    "    def add_train_value(self, value):\n",
    "        self.train_hist = np.append(self.train_hist, value)\n",
    "        \n",
    "    def add_test_value(self, value):\n",
    "        self.test_hist = np.append(self.test_hist, value)\n",
    "        \n",
    "    def clear_and_plot(self):\n",
    "        clear_output(wait=True)\n",
    "        plt.plot(np.arange(0, len(self.train_hist)), self.train_hist, label='Train')\n",
    "        plt.plot(np.arange(0, len(self.test_hist)), self.test_hist, label='Test')\n",
    "        plt.legend()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dec060f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer:\n",
    "    def __init__(self, model, device, logger, train_loader, test_loader, num_epochs, start_lr=1e-4, end_lr=1e-4, weight_decay=0):\n",
    "        self.model = model\n",
    "        self.device = device\n",
    "        self.logger = logger\n",
    "        self.train_loader = train_loader\n",
    "        self.test_loader = test_loader\n",
    "        self.num_epochs = num_epochs\n",
    "        \n",
    "        self.optimizer = optim.Adam(model.parameters(), lr=start_lr, weight_decay=weight_decay)\n",
    "        self.scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(self.optimizer, T_max=num_epochs, eta_min=end_lr)\n",
    "        \n",
    "    def generate_new_filename(self):\n",
    "        start = \"autosaves/opticla_flow_network_autosave_\"\n",
    "        i = 0\n",
    "        while os.path.isfile(f\"{start}{i}.pth\"):\n",
    "            i += 1\n",
    "        return f\"{start}{i}.pth\"\n",
    "\n",
    "    \n",
    "    def edge_aware_smoothness_loss(self, flow, image, alpha=100.0):\n",
    "        # Compute image gradients\n",
    "        grad_x = torch.mean(torch.abs(image[:, :, :, :-1] - image[:, :, :, 1:]), axis = 1)\n",
    "        grad_y = torch.mean(torch.abs(image[:, :, :-1, :] - image[:, :, 1:, :]), axis = 1)\n",
    "        \n",
    "        # Compute flow gradients\n",
    "        flow_grad_x = torch.mean(torch.abs(flow[:, :, :, :-1] - flow[:, :, :, 1:]), axis = 1)\n",
    "        flow_grad_y = torch.mean(torch.abs(flow[:, :, :-1, :] - flow[:, :, 1:, :]), axis = 1)\n",
    "        \n",
    "        # Weight by image gradients (edge-aware)\n",
    "        loss_x = (torch.exp(-alpha * grad_x) * flow_grad_x).mean()\n",
    "        loss_y = (torch.exp(-alpha * grad_y) * flow_grad_y).mean()\n",
    "        \n",
    "        return loss_x + loss_y\n",
    "    \n",
    "    def calculate_loss(self, outputs, target, frames_A, smoothness_strength = 5.0):\n",
    "        mse_loss = torch.mean((outputs - target)**2)\n",
    "        smoothness_loss = self.edge_aware_smoothness_loss(outputs, frames_A)\n",
    "        return mse_loss +  smoothness_loss  * smoothness_strength\n",
    "        \n",
    "    def transfer(self, data, device):\n",
    "        return [item.to(device) for item in data]\n",
    "\n",
    "    def process_epoch(self, data_loader, mode=\"train\"):\n",
    "        total_loss = 0.0\n",
    "        count = 0\n",
    "        self.model.train() if mode == \"train\" else self.model.eval()\n",
    "        for batch in data_loader:\n",
    "            count += 1\n",
    "            if count == 256:\n",
    "                break\n",
    "            \n",
    "            frames_A, frames_B, target_flow = batch\n",
    "\n",
    "            with torch.set_grad_enabled(mode == \"train\"):\n",
    "                outputs = self.model(frames_A, frames_B)\n",
    "                flow = outputs\n",
    "                flow = (torch.tanh(flow)+1.0)/2.0\n",
    "\n",
    "                loss = self.calculate_loss(flow, target_flow, frames_A)\n",
    "\n",
    "                if mode == \"train\":\n",
    "                    self.optimizer.zero_grad()\n",
    "                    loss.backward()\n",
    "                    self.optimizer.step()\n",
    "               \n",
    "            # show\n",
    "            with torch.no_grad():\n",
    "                if mode == \"show\":\n",
    "                    plt.figure(figsize=(10, 6))\n",
    "                    batch_size = frames_A.shape[0]\n",
    "                    void_channel = torch.ones([batch_size, 1, image_size[0], image_size[1]]).to(device) * 0.5\n",
    "                    target_flow = torch.cat([target_flow, void_channel], 1)\n",
    "                    outputs = torch.cat([flow, void_channel], 1)\n",
    "                    \n",
    "                    num_examples = min(6, batch_size)\n",
    "                    for i in range(num_examples):\n",
    "                        ax = plt.subplot(4, num_examples, num_examples * 0 + i + 1)\n",
    "                        plt.imshow(frames_A[i].permute(1, 2, 0).cpu().numpy())\n",
    "                        plt.axis(\"off\")\n",
    "\n",
    "                        ax = plt.subplot(4, num_examples, num_examples * 1 + i + 1)\n",
    "                        plt.imshow(frames_B[i].permute(1, 2, 0).cpu().numpy())\n",
    "                        plt.axis(\"off\")\n",
    "\n",
    "                        ax = plt.subplot(4, num_examples, num_examples * 2 + i + 1)\n",
    "                        plt.imshow(target_flow[i].permute(1, 2, 0).cpu().numpy())\n",
    "                        plt.axis(\"off\")\n",
    "\n",
    "                        ax = plt.subplot(4, num_examples, num_examples * 3 + i + 1)\n",
    "                        plt.imshow(outputs[i].permute(1, 2, 0).cpu().numpy())\n",
    "                        plt.axis(\"off\")\n",
    "\n",
    "                    plt.show()\n",
    "                    \n",
    "                    # use only the first batch to show\n",
    "                    break\n",
    "\n",
    "            total_loss += loss.item()\n",
    "        \n",
    "        mean_loss = total_loss / count\n",
    "        return mean_loss\n",
    "\n",
    "    def train(self):\n",
    "        try:\n",
    "            for epoch in range(self.num_epochs):\n",
    "                print(f\"Running epoch {epoch+1}/{self.num_epochs}\")\n",
    "                \n",
    "                # Training phase\n",
    "                train_loss = self.process_epoch(self.train_loader, mode=\"train\")\n",
    "                self.logger.add_train_value(train_loss)\n",
    "                print(f\"Train Loss: {train_loss}\")\n",
    "                \n",
    "                # Testing phase\n",
    "                if self.test_loader:\n",
    "                    test_loss = self.process_epoch(self.test_loader, mode=\"test\")\n",
    "                    self.logger.add_test_value(test_loss)\n",
    "                    print(f\"Test Loss: {test_loss}\")\n",
    "                \n",
    "                # Learning rate and scheduler\n",
    "                current_lr = self.optimizer.param_groups[0]['lr']\n",
    "                print(f\"Current LR: {current_lr}\")\n",
    "                self.scheduler.step()\n",
    "\n",
    "                # Plot and clear the logger for the next iteration\n",
    "                self.logger.clear_and_plot()\n",
    "                \n",
    "                # Show phase\n",
    "                self.process_epoch(self.train_loader, mode=\"show\")\n",
    "\n",
    "                if (epoch % 100 == 2):\n",
    "                    filename = self.generate_new_filename()\n",
    "                    torch.save(self.model.state_dict(), filename)\n",
    "                    print(f\"Model saved as {filename}\")\n",
    "\n",
    "        except KeyboardInterrupt:\n",
    "            print(\"Training interrupted by user.\")\n",
    "\n",
    "        # Save model\n",
    "        #filename = self.generate_new_filename()\n",
    "        #torch.save(self.model.state_dict(), filename)\n",
    "        #print(f\"Model saved as {filename}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db3a0387",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = VisualDataLogger()\n",
    "#model = OpticalFlowNetwork().to(device)\n",
    "#model.encoder.backbone.load_state_dict(torch.load(\"mobilenet_3_blocks.pth\", weights_only = True))\n",
    "model.encoder.backbone.requires_grad = True\n",
    "num_epochs = 1000\n",
    "trainer = Trainer(model, device, logger, loader, None, num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17af2871",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31b6318c",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.process_epoch(trainer.train_loader, mode=\"show\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2052e066",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sum(p.numel() for p in model.parameters() if p.requires_grad))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04a2c930",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"micron-flow-beta-0.1.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eebb04e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a99408b2-98ce-481f-a6e3-d89951911932",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44a29faa-efc3-4903-b631-20e6395ce3d1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
