{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3cbb9cda",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from torchvision.io import decode_image, decode_jpeg\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as T\n",
    "from torchvision.models.optical_flow import raft_large\n",
    "from torchvision.utils import flow_to_image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch import Tensor\n",
    "import random\n",
    "import time\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1fe9a828",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MobileNetV2ConvLayer(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride=1, groups=1, activation=True):\n",
    "        super().__init__()\n",
    "        padding = (kernel_size - 1) // 2\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size, stride,padding, groups=groups, bias=False)\n",
    "        self.bn = nn.BatchNorm2d(out_channels, eps=0.001, momentum=0.997)\n",
    "        self.activation = nn.ReLU6() if activation else None\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.bn(x)\n",
    "        if self.activation:\n",
    "            x = self.activation(x)\n",
    "        return x\n",
    "\n",
    "class MobileNetV2InvertedResidual(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, stride, expand_ratio):\n",
    "        super().__init__()\n",
    "        hidden_dim = in_channels * expand_ratio\n",
    "        \n",
    "        self.expand_1x1 = MobileNetV2ConvLayer(in_channels, hidden_dim, 1, activation=True)\n",
    "        self.conv_3x3 = MobileNetV2ConvLayer(hidden_dim, hidden_dim, 3, stride=stride, groups=hidden_dim, activation=True)                          \n",
    "        self.reduce_1x1 = MobileNetV2ConvLayer(hidden_dim, out_channels, 1, activation=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "        \n",
    "        x = self.expand_1x1(x)\n",
    "        x = self.conv_3x3(x)\n",
    "        x = self.reduce_1x1(x)\n",
    "        \n",
    "        if x.shape == identity.shape:\n",
    "            x = x + identity\n",
    "        return x\n",
    "        \n",
    "\n",
    "class Backbone(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv_stem = nn.Sequential(\n",
    "            MobileNetV2ConvLayer(3, 32, 3, stride=2),\n",
    "            MobileNetV2ConvLayer(32, 32, 3, groups=32),\n",
    "            MobileNetV2ConvLayer(32, 16, 1, activation=False)\n",
    "        )\n",
    "\n",
    "        self.block1 = MobileNetV2InvertedResidual(16, 24, stride=2, expand_ratio=6)\n",
    "        self.block2 = MobileNetV2InvertedResidual(24, 24, stride=1, expand_ratio=6)\n",
    "        self.block3 = MobileNetV2InvertedResidual(24, 32, stride=2, expand_ratio=6)\n",
    "       \n",
    "        \n",
    "    def forward(self, x):\n",
    "        out1 = self.conv_stem(x)\n",
    "        x = self.block1(out1)\n",
    "        out2 = self.block2(x)\n",
    "        out3 = self.block3(out2)\n",
    "        return out1, out2, out3\n",
    "\n",
    "class CombinedEncoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.backbone = Backbone()\n",
    "\n",
    "        self.image_conv = nn.Conv2d(3, 8, kernel_size=3, padding=1)\n",
    "        self.batch_norm = nn.BatchNorm2d(8)\n",
    "        self.activation = nn.ReLU(inplace=True)\n",
    "\n",
    "    def forward(self, image):\n",
    "        out2, out3, out4 = self.backbone(image)\n",
    "\n",
    "        x = self.image_conv(image)\n",
    "        x = self.batch_norm(x)\n",
    "        out1 = self.activation(x)\n",
    "\n",
    "        return out1, out2, out3, out4\n",
    "\n",
    "class FlowEncoderResidualBlock(nn.Module):\n",
    "    def __init__(self, input_channels, hidden_channels, output_channels):\n",
    "        super(FlowEncoderResidualBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(input_channels, hidden_channels, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(hidden_channels, output_channels, kernel_size=3, padding=1)\n",
    "        self.batch_norm1 = nn.BatchNorm2d(hidden_channels)\n",
    "        self.batch_norm2 = nn.BatchNorm2d(output_channels)\n",
    "        self.residual_conv = nn.Conv2d(input_channels, output_channels, kernel_size=1, bias=False)\n",
    "        self.activation = nn.ReLU(inplace=True)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        residual = self.residual_conv(x)\n",
    "        \n",
    "        x = self.conv1(x)\n",
    "        x = self.batch_norm1(x)\n",
    "        x = self.activation(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.batch_norm2(x)\n",
    "        \n",
    "        x = x + residual\n",
    "        x = self.activation(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "class FlowEncoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.block1 = FlowEncoderResidualBlock(8 * 2, 32, 16)\n",
    "        self.block2 = FlowEncoderResidualBlock(16 * 2 + 16, 32, 16)\n",
    "        self.block3 = FlowEncoderResidualBlock(24 * 2 + 16, 64, 32)\n",
    "        self.block4 = FlowEncoderResidualBlock(32 * 2 + 32, 128, 32)\n",
    "\n",
    "        self.pooling = nn.AvgPool2d(2)\n",
    "        \n",
    "    def forward(self, encoder_A_output, encoder_B_output):\n",
    "        A1, A2, A3, A4 = encoder_A_output\n",
    "        B1, B2, B3, B4 = encoder_B_output\n",
    "\n",
    "        x = torch.cat([A1, B1], axis = 1)\n",
    "        block1_output = self.block1(x)\n",
    "        x = self.pooling(block1_output)\n",
    "\n",
    "        x = torch.cat([A2, B2, x], axis = 1)\n",
    "        block2_output = self.block2(x)\n",
    "        x = self.pooling(block2_output)\n",
    "\n",
    "        x = torch.cat([A3, B3, x], axis = 1)\n",
    "        block3_output = self.block3(x)\n",
    "        x = self.pooling(block3_output)\n",
    "\n",
    "        x = torch.cat([A4, B4, x], axis = 1)\n",
    "        block4_output = self.block4(x)\n",
    "        \n",
    "        return block1_output, block2_output, block3_output, block4_output\n",
    "\n",
    "class FlowRefiner(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(FlowRefiner, self).__init__()\n",
    "        \n",
    "        self.consistency_residual1 = FlowEncoderResidualBlock(32, 64, 32)\n",
    "        self.consistency_residual2 = FlowEncoderResidualBlock(32 + 32, 64, 32)\n",
    "        \n",
    "        self.internal_consistency_residual = FlowEncoderResidualBlock(32, 64, 32)\n",
    "        \n",
    "        self.pooling = nn.AvgPool2d(2)\n",
    "        \n",
    "    def forward(self, input_flow):\n",
    "        \n",
    "        residual_connection = self.consistency_residual1(input_flow)\n",
    "        \n",
    "        x = self.pooling(residual_connection)\n",
    "        x = self.internal_consistency_residual(x)\n",
    "        \n",
    "        x = F.interpolate(\n",
    "            x, \n",
    "            size=residual_connection.shape[2:],\n",
    "            mode='bilinear', \n",
    "            align_corners=False\n",
    "        )\n",
    "        \n",
    "        x = torch.cat([x, input_flow], axis = 1)\n",
    "        x = self.consistency_residual2(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "class UpscaleBlock(nn.Module):\n",
    "    def __init__(self, base_channels, details_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.upsample = nn.Upsample(scale_factor=2, mode=\"bilinear\", align_corners=False)\n",
    "\n",
    "        self.block = FlowEncoderResidualBlock(base_channels + details_channels, out_channels * 2, out_channels)\n",
    "\n",
    "    def forward(self, base, details):\n",
    "        upsampled_base = self.upsample(base)\n",
    "\n",
    "        x = torch.cat([upsampled_base, details], axis = 1)\n",
    "        x = self.block(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "class FlowDecoder(nn.Module):  \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.upscale_block1 = UpscaleBlock(32, 32, 32)\n",
    "        self.upscale_block2 = UpscaleBlock(32, 16, 32)\n",
    "        self.upscale_block3 = UpscaleBlock(32, 16, 16)\n",
    "\n",
    "        self.linear = nn.Conv2d(16, 2, kernel_size=1)\n",
    "        \n",
    "    def forward(self, flows):\n",
    "        f1, f2, f3, f4 = flows\n",
    "        \n",
    "        x = self.upscale_block1(f4, f3)\n",
    "        x = self.upscale_block2(x, f2)\n",
    "        x = self.upscale_block3(x, f1)\n",
    "\n",
    "        x = self.linear(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "\n",
    "class OpticalFlowNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.encoder = CombinedEncoder()\n",
    "        self.flow_encoder = FlowEncoder()\n",
    "        self.flow_decoder = FlowDecoder()\n",
    "        self.flow_refiner = FlowRefiner()\n",
    "\n",
    "    def forward(self, frameA, frameB):\n",
    "        encoder_A_output = self.encoder(frameA)\n",
    "        encoder_B_output = self.encoder(frameB)\n",
    "        flows = self.flow_encoder(encoder_A_output, encoder_B_output)\n",
    "        f1, f2, f3, f4 = flows\n",
    "        f4 = self.flow_refiner(f4)\n",
    "        flows = f1, f2, f3, f4\n",
    "        flow = self.flow_decoder(flows)\n",
    "        \n",
    "        return flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ef72ca58",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = OpticalFlowNetwork()\n",
    "model.load_state_dict(torch.load(\"micron-flow-beta-0.1.pth\", weights_only = True))\n",
    "model = model.to(device).eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "433dfbc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.02394556999206543\n",
      "0.012676715850830078\n",
      "0.012248992919921875\n",
      "0.012222766876220703\n",
      "0.012387275695800781\n",
      "0.012253761291503906\n",
      "0.012729406356811523\n",
      "0.012178897857666016\n",
      "0.012613534927368164\n",
      "0.012687206268310547\n",
      "0.014333486557006836\n",
      "0.012476921081542969\n",
      "0.011945962905883789\n",
      "0.012471675872802734\n",
      "0.012022733688354492\n",
      "0.012076854705810547\n",
      "0.011684656143188477\n",
      "0.01169133186340332\n",
      "0.014392614364624023\n",
      "0.012199878692626953\n",
      "0.012138605117797852\n",
      "0.011540412902832031\n",
      "0.01169729232788086\n",
      "0.012212514877319336\n",
      "0.011911392211914062\n",
      "0.013893842697143555\n",
      "0.013659000396728516\n",
      "0.012888431549072266\n",
      "0.011305093765258789\n",
      "0.013258934020996094\n",
      "0.011907577514648438\n",
      "0.012003183364868164\n",
      "0.012407541275024414\n",
      "0.011663675308227539\n",
      "0.011890649795532227\n",
      "0.011796712875366211\n",
      "0.011845111846923828\n",
      "0.012089014053344727\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.014444351196289062\n",
      "0.012444734573364258\n",
      "0.018328189849853516\n",
      "0.009999752044677734\n",
      "0.010007619857788086\n",
      "0.010994434356689453\n",
      "0.01298975944519043\n",
      "0.010986804962158203\n",
      "0.0165402889251709\n",
      "0.009997367858886719\n",
      "0.012990236282348633\n",
      "0.012992620468139648\n",
      "0.009996891021728516\n",
      "0.015995264053344727\n",
      "0.015016555786132812\n",
      "0.03302454948425293\n",
      "0.017011404037475586\n",
      "0.011003732681274414\n",
      "0.010000228881835938\n",
      "0.010406255722045898\n",
      "0.02199864387512207\n",
      "0.010998964309692383\n",
      "0.011537790298461914\n",
      "0.031011104583740234\n",
      "0.016997575759887695\n",
      "0.012998580932617188\n",
      "0.011998653411865234\n",
      "0.014997005462646484\n",
      "0.015535116195678711\n",
      "0.012993574142456055\n",
      "0.010999679565429688\n",
      "0.01100611686706543\n",
      "0.009999990463256836\n",
      "0.010999679565429688\n",
      "0.012991189956665039\n",
      "0.009994983673095703\n",
      "0.016994953155517578\n",
      "0.013997793197631836\n",
      "0.011998176574707031\n",
      "0.0110015869140625\n",
      "0.011013984680175781\n",
      "0.0319972038269043\n",
      "0.019998550415039062\n",
      "0.0149993896484375\n",
      "0.011995553970336914\n",
      "0.009999275207519531\n",
      "0.01598072052001953\n",
      "0.013998031616210938\n",
      "0.011986732482910156\n",
      "0.010990381240844727\n",
      "0.026541948318481445\n",
      "0.018001556396484375\n",
      "0.027996540069580078\n",
      "0.01900005340576172\n",
      "0.011996030807495117\n",
      "0.01499795913696289\n",
      "0.010994195938110352\n",
      "0.011994123458862305\n",
      "0.010998964309692383\n",
      "0.009999275207519531\n",
      "0.009999752044677734\n",
      "0.01398921012878418\n",
      "0.03099536895751953\n",
      "0.017992734909057617\n",
      "0.014998674392700195\n",
      "0.016010522842407227\n",
      "0.011985540390014648\n",
      "0.012520074844360352\n",
      "0.011054277420043945\n",
      "0.017470836639404297\n",
      "0.011716604232788086\n",
      "0.0110015869140625\n",
      "0.009999275207519531\n",
      "0.010999679565429688\n",
      "0.010524749755859375\n",
      "0.010996580123901367\n",
      "0.014020919799804688\n",
      "0.012998819351196289\n",
      "0.011001825332641602\n",
      "0.010997295379638672\n",
      "0.013999462127685547\n",
      "0.012987852096557617\n"
     ]
    }
   ],
   "source": [
    "# Open video capture\n",
    "image_size = (152, 240)\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "if not cap.isOpened():\n",
    "    raise IOError(\"Cannot open webcam\")\n",
    "\n",
    "prev_frame = None\n",
    "prev_output = None\n",
    "\n",
    "with torch.no_grad():\n",
    "    while True:\n",
    "        # Capture frame\n",
    "    \n",
    "        time.sleep(0.01)\n",
    "        ret, frame = cap.read()\n",
    "        \n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        # Preprocess frame\n",
    "        frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        resized_frame = cv2.resize(frame_rgb, (image_size[1], image_size[0]), interpolation = cv2.INTER_AREA)\n",
    "        tensor_frame = torch.from_numpy(resized_frame).permute(2, 0, 1).float() / 255.0\n",
    "        tensor_frame = tensor_frame.unsqueeze(0).to(device)  # Add batch dimension\n",
    "\n",
    "        if prev_frame is not None:\n",
    "            cur = time.time()\n",
    "            if torch.equal(tensor_frame, prev_frame):\n",
    "                continue\n",
    "            flow = model(tensor_frame, prev_frame)\n",
    "            print(time.time() - cur)\n",
    "            #void_channel = torch.ones([1, image_size[0], image_size[1]]).to(device) * 128\n",
    "            #flow_img = torch.clip(torch.cat([(flow[0] * 255), void_channel]), 0, 255).permute(1, 2, 0).cpu().numpy()\n",
    "            flow = flow[0]\n",
    "            flow[0, 0, 0] = -1\n",
    "            flow[0, 0, 1] = 1\n",
    "            flow_img = flow_to_image(flow).permute(1, 2, 0).cpu().numpy()\n",
    "            if prev_output is not None:\n",
    "                smoothness = 0.0\n",
    "                prev_output = prev_output * smoothness + flow_img * (1.0 - smoothness)\n",
    "                \n",
    "            else:\n",
    "                prev_output = flow_img\n",
    "                \n",
    "            flow_img = prev_output.astype(np.uint8)\n",
    "            \n",
    "            flow_display = cv2.resize(flow_img, (960*2, 520*2))\n",
    "            \n",
    "            # Display result\n",
    "            cv2.imshow('Optical Flow', flow_display)\n",
    "\n",
    "        prev_frame = tensor_frame.clone()\n",
    "\n",
    "        # Exit on 'q' press\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26f135a7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
